{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jsr_Xl5LBVNr"
   },
   "source": [
    "# ICT707 Task 1 Test\n",
    "\n",
    "\n",
    "### Instructions\n",
    "\n",
    "* This assignment will be done completely inside this Jupyter notebook.\n",
    "* You have 60 minutes. When you have finished, this notebook is the only file that you will need to submit to Blackboard.\n",
    "* You have five tasks to complete in this Notebook. 2 marks for each with a total of 10 marks.\n",
    "* Make sure you fill in any place that says YOUR CODE HERE.\n",
    "\n",
    "* If you see any error related to spark context, please **run the last cell** and then retry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "czZCbsXABVNs"
   },
   "outputs": [],
   "source": [
    "# Please enter your NAME and student ID\n",
    "NAME = \"\"\n",
    "ID = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JYggDOZMBiqc"
   },
   "source": [
    "# PySpark Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LoRLSnOtBXzn"
   },
   "outputs": [],
   "source": [
    "# Please run this cell to get Java and spark installed\n",
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
    "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
    "!pip install pyspark==2.4.6\n",
    "\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OF2ByTgJBnIE"
   },
   "source": [
    "# Connect GDrive for data set files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "muPOGMTfBr2s"
   },
   "outputs": [],
   "source": [
    "# Mount the cloud folder for data file storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H0FqMLY0GEU_"
   },
   "outputs": [],
   "source": [
    "# Make sure you have relevant data files uploaded\n",
    "# And then use the correct data file names below\n",
    "txtFile = \"/content/gdrive/My Drive/Colab Notebooks/PrideAndPrejudice.txt\"\n",
    "csvFile = \"/content/gdrive/My Drive/Colab Notebooks/UserPurchaseHistory.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IxrL34e0BVNw"
   },
   "source": [
    "## PART I: Use Spark to process text files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xhtlKfEQBVNw"
   },
   "source": [
    "### Task 1: Get the spark context ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFV1zQwVBVNx"
   },
   "outputs": [],
   "source": [
    "# add imports here\n",
    "#YOUR CODE HERE\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHCL8PGOaUh4"
   },
   "outputs": [],
   "source": [
    "# create SparkContext\n",
    "#YOUR CODE HERE\n",
    "# sc = ____\n",
    "sc=SparkContext('local', 'First Spark SQL app')\n",
    "sc=SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0tOPh59BVNz"
   },
   "source": [
    "### Task 2: Load the file and count the word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iIhcvCWjBVN0"
   },
   "outputs": [],
   "source": [
    "# load the text file \"PrideAndPrejudice.txt\" into variable file_rdd\n",
    "#YOUR CODE HERE\n",
    "# file_rdd = ______\n",
    "file_rdd = sc.textFile(txtFile)\n",
    "\n",
    "# print the number of lines containing word \"happy\" ignoring the case\n",
    "#YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "wmTzoQlhfCXs",
    "outputId": "5967f8a3-a3d3-4174-b267-6bd8a73f5a6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good-humoured, lively; and I never saw such happy manners!--so much',\n",
       " 'advantages, and I can be equally happy in either.”',\n",
       " 'with the idea; and you may imagine that I am happy on every occasion to',\n",
       " '“You judge very properly,” said Mr. Bennet, “and it is happy for you',\n",
       " 'him the day before from town, and he was happy to say had accepted a']"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_rdd = file_rdd.filter(lambda x: \"happy\" in x.lower())\n",
    "happy_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QQqKWtAoBVN2"
   },
   "source": [
    "## PART II: Use Spark SQL to process structure data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dIRoLje_BVN2"
   },
   "source": [
    "### Task 3: Load the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Qre3g_psBVN3",
    "outputId": "2b312576-f694-455a-ac7b-8c8fbdf01473"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Name: string, Type: string, Price: string]\n",
      "+----+--------------+-----+\n",
      "|Name|          Type|Price|\n",
      "+----+--------------+-----+\n",
      "|John|        iPhone| 9.99|\n",
      "|John|   Headsphones| 5.49|\n",
      "|Jack|        iPhone| 9.99|\n",
      "|Jill|Samsung Galaxy| 8.95|\n",
      "| Bob|    iPad Cover| 5.49|\n",
      "+----+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# add imports for SQLContext here\n",
    "# beware that you have create SparkContext previously\n",
    "#YOUR CODE HERE\n",
    "sqlContext = SQLContext(sc)\n",
    "data_df = sqlContext.read.csv(csvFile , header = True)\n",
    "print(data_df)\n",
    "data_df.show()\n",
    "\n",
    "# create SQLContext\n",
    "#YOUR CODE HERE\n",
    "# sqlContext = ____\n",
    "\n",
    "# load the csv file \"UserPurchaseHistory.csv\" into variable data_df\n",
    "#YOUR CODE HERE\n",
    "# data_df = _____\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rSe3wVbwBVN5"
   },
   "source": [
    "### Task 4: Selection and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "BS9sO8E5BVN5",
    "outputId": "6a69513f-105c-4807-8c3c-7385b0a9ced0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Name|\n",
      "+----+\n",
      "|Jack|\n",
      "| Bob|\n",
      "|John|\n",
      "|Jill|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for Type \"iPhone\", choose \"Name\" and \"Price\" attributes to show, and order them based on \"Price\"\n",
    "#YOUR CODE HERE\n",
    "data_df.select('Name').distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fIKZAjIkBVN8"
   },
   "source": [
    "### Task 5: Filtering and aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IF--IqwUBVN8",
    "outputId": "da60e984-7862-4168-ceba-4cc7f9df2b86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the number of purchases for each customer\n",
    "#YOUR CODE HERE\n",
    "data_df.registerTempTable('data_table')\n",
    "names = sqlContext.sql(\"\"\"SELECT Name FROM data_table ORDER BY Name LIMIT 10\"\"\")\n",
    "display(names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Inodh_mrBVN_"
   },
   "source": [
    "## Shut down SparkContext when exiting\n",
    "\n",
    "If you have error messages related to sparkContext, try to run the following cell, and then rerun all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8IRm1qMaBVN_"
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6swumMleBVOB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ICT707_T1_Sample_Test_Colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
